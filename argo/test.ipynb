{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xmlfile = pd.read_xml(\"/Volumes/Samsung_T5/argo/deltas.dfxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>execution_environment</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>partition_offset</th>\n",
       "      <th>block_size</th>\n",
       "      <th>ftype</th>\n",
       "      <th>ftype_str</th>\n",
       "      <th>block_count</th>\n",
       "      <th>first_block</th>\n",
       "      <th>last_block</th>\n",
       "      <th>original_volume</th>\n",
       "      <th>fileobject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disk image difference set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Storage/mtlaam/tmp/workflow/diskprint...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>105906176.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ntfs</td>\n",
       "      <td>5216767.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5216766.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ntfs</td>\n",
       "      <td>25599.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25598.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        type  execution_environment  \\\n",
       "0  Disk image difference set                    NaN   \n",
       "1                       None                    NaN   \n",
       "2                       None                    NaN   \n",
       "3                       None                    NaN   \n",
       "4                       None                    NaN   \n",
       "\n",
       "                                      image_filename  partition_offset  \\\n",
       "0                                               None               NaN   \n",
       "1                                               None               NaN   \n",
       "2  /Volumes/Storage/mtlaam/tmp/workflow/diskprint...               NaN   \n",
       "3                                               None       105906176.0   \n",
       "4                                               None         1048576.0   \n",
       "\n",
       "   block_size  ftype ftype_str  block_count  first_block  last_block  \\\n",
       "0         NaN    NaN      None          NaN          NaN         NaN   \n",
       "1         NaN    NaN      None          NaN          NaN         NaN   \n",
       "2         NaN    NaN      None          NaN          NaN         NaN   \n",
       "3      4096.0    1.0      ntfs    5216767.0          0.0   5216766.0   \n",
       "4      4096.0    1.0      ntfs      25599.0          0.0     25598.0   \n",
       "\n",
       "   original_volume  fileobject  \n",
       "0              NaN         NaN  \n",
       "1              NaN         NaN  \n",
       "2              NaN         NaN  \n",
       "3              NaN         NaN  \n",
       "4              NaN         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfxml\n",
    "iters = dfxml.iter_dfxml('/Volumes/Samsung_T5/M57/pat-2009-12-10.raw.xml', preserve_elements=True)\n",
    "obj_list = []\n",
    "for obj in iters:\n",
    "    obj_list.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49745\n"
     ]
    }
   ],
   "source": [
    "print(len(obj_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = obj_list[34485] #28982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WINDOWS/system32/dllcache/fpexedll.dll'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TIMETAGLIST', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_byte_runs', '_tags', 'allocated', 'allocated_inode', 'allocated_name', 'atime', 'byte_runs', 'compressed', 'content_for_run', 'contents', 'crtime', 'ctime', 'dtime', 'encrypted', 'ext', 'file_present', 'filename', 'filesize', 'frag_start_sector', 'fragments', 'gid', 'has_contents', 'has_sector', 'has_tag', 'hashdigest', 'imagefile', 'inode', 'is_dir', 'is_file', 'is_virtual', 'libmagic', 'md5', 'meta_type', 'mode', 'mtime', 'name_type', 'partition', 'savefile', 'sha1', 'sha256', 'tag', 'tempfile', 'times', 'uid', 'volume', 'xml_element']\n"
     ]
    }
   ],
   "source": [
    "print(dir(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dfxml.byte_run at 0x7fc25ae60220>,\n",
       " <dfxml.byte_run at 0x7fc25ae60250>,\n",
       " <dfxml.byte_run at 0x7fc25ae60280>,\n",
       " <dfxml.byte_run at 0x7fc25ae602b0>,\n",
       " <dfxml.byte_run at 0x7fc25ae602e0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.byte_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'decode_sax_attributes', 'decode_xml_attributes', 'extra_len', 'file_offset', 'fs_offset', 'has_sector', 'hashdigest', 'img_offset', 'len', 'sector_count', 'sector_size', 'start_sector', 'uncompressed_len']\n"
     ]
    }
   ],
   "source": [
    "print(dir(a.byte_runs()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.byte_runs()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = vars(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'img_offset': 5673254400, 'file_offset': 0, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'fs_offset': 5673222144, 'uncompressed_len': 8192}\n"
     ]
    }
   ],
   "source": [
    "print(type(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imagefile': None, 'hashdigest': {'md5': 'b4914a686146393c690dc0f78a0d5328', 'sha1': 'd317816485216cce9fcc44cd3cc5f46508ceab5a'}, '_tags': {'inode': '7685', 'parent_object': None, 'filename': 'WINDOWS/system32/dllcache/fpexedll.dll', 'partition': '1', 'id': '34486', 'name_type': 'r', 'filesize': '20541', 'alloc': '1', 'used': '1', 'compressed': '1', 'meta_type': '1', 'mode': '511', 'nlink': '1', 'uid': '0', 'gid': '0', 'mtime': '2003-03-25T00:52:04Z', 'ctime': '2009-11-09T00:31:15Z', 'atime': '2009-12-08T00:05:42Z', 'crtime': '2009-11-09T00:31:15Z', 'seq': '2', 'byte_run': '', 'byte_runs': None, 'md5': 'b4914a686146393c690dc0f78a0d5328', 'sha1': 'd317816485216cce9fcc44cd3cc5f46508ceab5a'}, '_byte_runs': [<dfxml.byte_run object at 0x7fc25ae60220>, <dfxml.byte_run object at 0x7fc25ae60250>, <dfxml.byte_run object at 0x7fc25ae60280>, <dfxml.byte_run object at 0x7fc25ae602b0>, <dfxml.byte_run object at 0x7fc25ae602e0>], 'volume': None, 'xml_element': <Element '{http://www.forensicswiki.org/wiki/Category:Digital_Forensics_XML}fileobject' at 0x7fc25ae3ce00>}\n",
      "34486\n"
     ]
    }
   ],
   "source": [
    "print(vars(a))\n",
    "print(a._tags['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_offset': 5673254400, 'file_offset': 0, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'fs_offset': 5673222144, 'uncompressed_len': 8192}\n",
      "start 11080575 stop 11080591\n",
      "id 34486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "sector_size = 512\n",
    "block_hashes_cols = ['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1']\n",
    "df = pd.DataFrame(columns=block_hashes_cols)\n",
    "p_img_offset = 0\n",
    "p_fs_offset = 0\n",
    "p_file_offset = 0\n",
    "p_len = 0\n",
    "print(c)\n",
    "p_img_offset = c['img_offset'] if c['img_offset'] else p_img_offset\n",
    "p_fs_offset = c['fs_offset'] if c['fs_offset'] else p_fs_offset\n",
    "p_file_offset = c['file_offset'] if c['file_offset'] else p_file_offset\n",
    "p_len = c['len'] if c['len'] else c['uncompressed_len'] if c['uncompressed_len'] else p_len\n",
    "start = p_img_offset//sector_size\n",
    "stop = (p_img_offset+p_len)//sector_size\n",
    "print(\"start\", start, \"stop\", stop, )\n",
    "df.loc[:,'img_sector_offset'] = np.arange(start, stop)\n",
    "print(\"id\", a._tags['id'])\n",
    "df.loc[:,'obj_id'] = a._tags['id'] #obj._tags['id']\n",
    "df.loc[:,'img_offset'] = np.arange(p_img_offset,p_img_offset+p_len,sector_size)\n",
    "df.loc[:,'fs_offset'] = np.arange(p_fs_offset,p_fs_offset+p_len,sector_size)\n",
    "df.loc[:,'file_offset'] = np.arange(p_file_offset,p_file_offset+p_len, sector_size)\n",
    "len_run = np.arange(p_len,0,-sector_size) #remaining_len\n",
    "sector_run = np.full(len(len_run), sector_size)\n",
    "len_run = np.minimum(len_run,sector_run)\n",
    "df.loc[:,'len'] = len_run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_id</th>\n",
       "      <th>img_offset</th>\n",
       "      <th>fs_offset</th>\n",
       "      <th>file_offset</th>\n",
       "      <th>len</th>\n",
       "      <th>md5</th>\n",
       "      <th>sha1</th>\n",
       "      <th>img_sector_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673254400</td>\n",
       "      <td>5673222144</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673254912</td>\n",
       "      <td>5673222656</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673255424</td>\n",
       "      <td>5673223168</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673255936</td>\n",
       "      <td>5673223680</td>\n",
       "      <td>1536</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673256448</td>\n",
       "      <td>5673224192</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673256960</td>\n",
       "      <td>5673224704</td>\n",
       "      <td>2560</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673257472</td>\n",
       "      <td>5673225216</td>\n",
       "      <td>3072</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673257984</td>\n",
       "      <td>5673225728</td>\n",
       "      <td>3584</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673258496</td>\n",
       "      <td>5673226240</td>\n",
       "      <td>4096</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673259008</td>\n",
       "      <td>5673226752</td>\n",
       "      <td>4608</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673259520</td>\n",
       "      <td>5673227264</td>\n",
       "      <td>5120</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673260032</td>\n",
       "      <td>5673227776</td>\n",
       "      <td>5632</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673260544</td>\n",
       "      <td>5673228288</td>\n",
       "      <td>6144</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673261056</td>\n",
       "      <td>5673228800</td>\n",
       "      <td>6656</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673261568</td>\n",
       "      <td>5673229312</td>\n",
       "      <td>7168</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673262080</td>\n",
       "      <td>5673229824</td>\n",
       "      <td>7680</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obj_id  img_offset   fs_offset  file_offset  len  md5 sha1  \\\n",
       "0   34486  5673254400  5673222144            0  512  NaN  NaN   \n",
       "1   34486  5673254912  5673222656          512  512  NaN  NaN   \n",
       "2   34486  5673255424  5673223168         1024  512  NaN  NaN   \n",
       "3   34486  5673255936  5673223680         1536  512  NaN  NaN   \n",
       "4   34486  5673256448  5673224192         2048  512  NaN  NaN   \n",
       "5   34486  5673256960  5673224704         2560  512  NaN  NaN   \n",
       "6   34486  5673257472  5673225216         3072  512  NaN  NaN   \n",
       "7   34486  5673257984  5673225728         3584  512  NaN  NaN   \n",
       "8   34486  5673258496  5673226240         4096  512  NaN  NaN   \n",
       "9   34486  5673259008  5673226752         4608  512  NaN  NaN   \n",
       "10  34486  5673259520  5673227264         5120  512  NaN  NaN   \n",
       "11  34486  5673260032  5673227776         5632  512  NaN  NaN   \n",
       "12  34486  5673260544  5673228288         6144  512  NaN  NaN   \n",
       "13  34486  5673261056  5673228800         6656  512  NaN  NaN   \n",
       "14  34486  5673261568  5673229312         7168  512  NaN  NaN   \n",
       "15  34486  5673262080  5673229824         7680  512  NaN  NaN   \n",
       "\n",
       "    img_sector_offset  \n",
       "0            11080575  \n",
       "1            11080576  \n",
       "2            11080577  \n",
       "3            11080578  \n",
       "4            11080579  \n",
       "5            11080580  \n",
       "6            11080581  \n",
       "7            11080582  \n",
       "8            11080583  \n",
       "9            11080584  \n",
       "10           11080585  \n",
       "11           11080586  \n",
       "12           11080587  \n",
       "13           11080588  \n",
       "14           11080589  \n",
       "15           11080590  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_offset': 5673254400, 'file_offset': 0, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'fs_offset': 5673222144, 'uncompressed_len': 8192}\n",
      "image offset 5673254400\n",
      "fs_offset 5673222144\n",
      "file_offset 0\n",
      "len 8192\n",
      "start 11080575 stop 11080591\n",
      "id 34486\n",
      "img_offsetE 5673262592 fs_offset 5673230336 file_offset 8192\n",
      "{'img_offset': None, 'file_offset': 8192, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'uncompressed_len': 4096}\n",
      "image offset 5673262592\n",
      "fs_offset 5673230336\n",
      "file_offset 8192\n",
      "len 4096\n",
      "start 11080591 stop 11080599\n",
      "id 34486\n",
      "img_offsetE 5673266688 fs_offset 5673234432 file_offset 12288\n",
      "{'img_offset': None, 'file_offset': 12288, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'uncompressed_len': 4096}\n",
      "image offset 5673266688\n",
      "fs_offset 5673234432\n",
      "file_offset 12288\n",
      "len 4096\n",
      "start 11080599 stop 11080607\n",
      "id 34486\n",
      "img_offsetE 5673270784 fs_offset 5673238528 file_offset 16384\n",
      "{'img_offset': None, 'file_offset': 16384, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'uncompressed_len': 4096}\n",
      "image offset 5673270784\n",
      "fs_offset 5673238528\n",
      "file_offset 16384\n",
      "len 4096\n",
      "start 11080607 stop 11080615\n",
      "id 34486\n",
      "img_offsetE 5673274880 fs_offset 5673242624 file_offset 20480\n",
      "{'img_offset': None, 'file_offset': 20480, 'len': None, 'sector_size': 512, 'hashdigest': {}, 'uncompressed_len': 61}\n",
      "image offset 5673274880\n",
      "fs_offset 5673242624\n",
      "file_offset 20480\n",
      "len 61\n",
      "start 11080615 stop 11080616\n",
      "id 34486\n",
      "img_offsetE 5673274941 fs_offset 5673242685 file_offset 20541\n"
     ]
    }
   ],
   "source": [
    "import dfxml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iters = dfxml.iter_dfxml('/Volumes/Samsung_T5/M57/pat-2009-12-10.raw.xml', preserve_elements=True)\n",
    "obj_list = []\n",
    "for obj in iters:\n",
    "    obj_list.append(obj)\n",
    "sector_size = 512   \n",
    "fobj = obj_list[34485]\n",
    "block_hashes_cols = ['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1']\n",
    "block_hash_df = pd.DataFrame(columns=block_hashes_cols)\n",
    "p_img_offset = 0\n",
    "p_fs_offset = 0\n",
    "p_file_offset = 0\n",
    "p_len = 0\n",
    "for byterun in fobj.byte_runs():\n",
    "    c = vars(byterun)\n",
    "    print(c)\n",
    "    p_img_offset = c['img_offset'] if (hasattr(byterun,'img_offset') and byterun.img_offset != None) else p_img_offset\n",
    "    print(\"image offset\", p_img_offset)\n",
    "    p_fs_offset = c['fs_offset'] if (hasattr(byterun,'fs_offset') and byterun.fs_offset != None) else p_fs_offset\n",
    "    print(\"fs_offset\", p_fs_offset)\n",
    "    p_file_offset = c['file_offset'] if (hasattr(byterun,'file_offset') and byterun.file_offset != None) else p_file_offset\n",
    "    print(\"file_offset\",p_file_offset)\n",
    "    p_len = byterun.len if (hasattr(byterun,'len') and byterun.len != None) else byterun.uncompressed_len if (hasattr(byterun,'uncompressed_len')and byterun.uncompressed_len != None) else p_len\n",
    "    print(\"len\", p_len)\n",
    "    start = p_img_offset//sector_size\n",
    "    stop = (p_img_offset+max(p_len,sector_size))//sector_size #(p_img_offset+max(p_len, sector_size))//sector_size\n",
    "    print(\"start\", start, \"stop\", stop, )\n",
    "    cols = ['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.loc[:,'img_sector_offset'] = np.arange(start, stop)\n",
    "    print(\"id\", a._tags['id'])\n",
    "    df.loc[:,'obj_id'] = a._tags['id'] #obj._tags['id']\n",
    "    df.loc[:,'img_offset'] = np.arange(p_img_offset,p_img_offset+p_len,sector_size)\n",
    "    df.loc[:,'fs_offset'] = np.arange(p_fs_offset,p_fs_offset+p_len,sector_size)\n",
    "    df.loc[:,'file_offset'] = np.arange(p_file_offset,p_file_offset+p_len, sector_size)\n",
    "    len_run = np.arange(p_len,0,-sector_size) #remaining_len\n",
    "    sector_run = np.full(len(len_run), sector_size)\n",
    "    len_run = np.minimum(len_run,sector_run)\n",
    "    df.loc[:,'len'] = len_run\n",
    "    block_hash_df = pd.concat([block_hash_df, df])\n",
    "    p_img_offset += p_len\n",
    "    p_fs_offset += p_len\n",
    "    p_file_offset += p_len\n",
    "    print(\"img_offsetE\", p_img_offset, \"fs_offset\", p_fs_offset, \"file_offset\", p_file_offset)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_id</th>\n",
       "      <th>img_offset</th>\n",
       "      <th>fs_offset</th>\n",
       "      <th>file_offset</th>\n",
       "      <th>len</th>\n",
       "      <th>md5</th>\n",
       "      <th>sha1</th>\n",
       "      <th>img_sector_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673254400</td>\n",
       "      <td>5673222144</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673254912</td>\n",
       "      <td>5673222656</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673255424</td>\n",
       "      <td>5673223168</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673255936</td>\n",
       "      <td>5673223680</td>\n",
       "      <td>1536</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673256448</td>\n",
       "      <td>5673224192</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673256960</td>\n",
       "      <td>5673224704</td>\n",
       "      <td>2560</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673257472</td>\n",
       "      <td>5673225216</td>\n",
       "      <td>3072</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673257984</td>\n",
       "      <td>5673225728</td>\n",
       "      <td>3584</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673258496</td>\n",
       "      <td>5673226240</td>\n",
       "      <td>4096</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673259008</td>\n",
       "      <td>5673226752</td>\n",
       "      <td>4608</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673259520</td>\n",
       "      <td>5673227264</td>\n",
       "      <td>5120</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673260032</td>\n",
       "      <td>5673227776</td>\n",
       "      <td>5632</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673260544</td>\n",
       "      <td>5673228288</td>\n",
       "      <td>6144</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673261056</td>\n",
       "      <td>5673228800</td>\n",
       "      <td>6656</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673261568</td>\n",
       "      <td>5673229312</td>\n",
       "      <td>7168</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673262080</td>\n",
       "      <td>5673229824</td>\n",
       "      <td>7680</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673262592</td>\n",
       "      <td>5673230336</td>\n",
       "      <td>8192</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673263104</td>\n",
       "      <td>5673230848</td>\n",
       "      <td>8704</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673263616</td>\n",
       "      <td>5673231360</td>\n",
       "      <td>9216</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673264128</td>\n",
       "      <td>5673231872</td>\n",
       "      <td>9728</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673264640</td>\n",
       "      <td>5673232384</td>\n",
       "      <td>10240</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673265152</td>\n",
       "      <td>5673232896</td>\n",
       "      <td>10752</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673265664</td>\n",
       "      <td>5673233408</td>\n",
       "      <td>11264</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673266176</td>\n",
       "      <td>5673233920</td>\n",
       "      <td>11776</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673266688</td>\n",
       "      <td>5673234432</td>\n",
       "      <td>12288</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673267200</td>\n",
       "      <td>5673234944</td>\n",
       "      <td>12800</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673267712</td>\n",
       "      <td>5673235456</td>\n",
       "      <td>13312</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673268224</td>\n",
       "      <td>5673235968</td>\n",
       "      <td>13824</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673268736</td>\n",
       "      <td>5673236480</td>\n",
       "      <td>14336</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673269248</td>\n",
       "      <td>5673236992</td>\n",
       "      <td>14848</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673269760</td>\n",
       "      <td>5673237504</td>\n",
       "      <td>15360</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673270272</td>\n",
       "      <td>5673238016</td>\n",
       "      <td>15872</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673270784</td>\n",
       "      <td>5673238528</td>\n",
       "      <td>16384</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673271296</td>\n",
       "      <td>5673239040</td>\n",
       "      <td>16896</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673271808</td>\n",
       "      <td>5673239552</td>\n",
       "      <td>17408</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673272320</td>\n",
       "      <td>5673240064</td>\n",
       "      <td>17920</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673272832</td>\n",
       "      <td>5673240576</td>\n",
       "      <td>18432</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673273344</td>\n",
       "      <td>5673241088</td>\n",
       "      <td>18944</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673273856</td>\n",
       "      <td>5673241600</td>\n",
       "      <td>19456</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673274368</td>\n",
       "      <td>5673242112</td>\n",
       "      <td>19968</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34486</td>\n",
       "      <td>5673274880</td>\n",
       "      <td>5673242624</td>\n",
       "      <td>20480</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11080615.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obj_id  img_offset   fs_offset file_offset  len  md5 sha1  \\\n",
       "0   34486  5673254400  5673222144           0  512  NaN  NaN   \n",
       "1   34486  5673254912  5673222656         512  512  NaN  NaN   \n",
       "2   34486  5673255424  5673223168        1024  512  NaN  NaN   \n",
       "3   34486  5673255936  5673223680        1536  512  NaN  NaN   \n",
       "4   34486  5673256448  5673224192        2048  512  NaN  NaN   \n",
       "5   34486  5673256960  5673224704        2560  512  NaN  NaN   \n",
       "6   34486  5673257472  5673225216        3072  512  NaN  NaN   \n",
       "7   34486  5673257984  5673225728        3584  512  NaN  NaN   \n",
       "8   34486  5673258496  5673226240        4096  512  NaN  NaN   \n",
       "9   34486  5673259008  5673226752        4608  512  NaN  NaN   \n",
       "10  34486  5673259520  5673227264        5120  512  NaN  NaN   \n",
       "11  34486  5673260032  5673227776        5632  512  NaN  NaN   \n",
       "12  34486  5673260544  5673228288        6144  512  NaN  NaN   \n",
       "13  34486  5673261056  5673228800        6656  512  NaN  NaN   \n",
       "14  34486  5673261568  5673229312        7168  512  NaN  NaN   \n",
       "15  34486  5673262080  5673229824        7680  512  NaN  NaN   \n",
       "0   34486  5673262592  5673230336        8192  512  NaN  NaN   \n",
       "1   34486  5673263104  5673230848        8704  512  NaN  NaN   \n",
       "2   34486  5673263616  5673231360        9216  512  NaN  NaN   \n",
       "3   34486  5673264128  5673231872        9728  512  NaN  NaN   \n",
       "4   34486  5673264640  5673232384       10240  512  NaN  NaN   \n",
       "5   34486  5673265152  5673232896       10752  512  NaN  NaN   \n",
       "6   34486  5673265664  5673233408       11264  512  NaN  NaN   \n",
       "7   34486  5673266176  5673233920       11776  512  NaN  NaN   \n",
       "0   34486  5673266688  5673234432       12288  512  NaN  NaN   \n",
       "1   34486  5673267200  5673234944       12800  512  NaN  NaN   \n",
       "2   34486  5673267712  5673235456       13312  512  NaN  NaN   \n",
       "3   34486  5673268224  5673235968       13824  512  NaN  NaN   \n",
       "4   34486  5673268736  5673236480       14336  512  NaN  NaN   \n",
       "5   34486  5673269248  5673236992       14848  512  NaN  NaN   \n",
       "6   34486  5673269760  5673237504       15360  512  NaN  NaN   \n",
       "7   34486  5673270272  5673238016       15872  512  NaN  NaN   \n",
       "0   34486  5673270784  5673238528       16384  512  NaN  NaN   \n",
       "1   34486  5673271296  5673239040       16896  512  NaN  NaN   \n",
       "2   34486  5673271808  5673239552       17408  512  NaN  NaN   \n",
       "3   34486  5673272320  5673240064       17920  512  NaN  NaN   \n",
       "4   34486  5673272832  5673240576       18432  512  NaN  NaN   \n",
       "5   34486  5673273344  5673241088       18944  512  NaN  NaN   \n",
       "6   34486  5673273856  5673241600       19456  512  NaN  NaN   \n",
       "7   34486  5673274368  5673242112       19968  512  NaN  NaN   \n",
       "0   34486  5673274880  5673242624       20480   61  NaN  NaN   \n",
       "\n",
       "    img_sector_offset  \n",
       "0          11080575.0  \n",
       "1          11080576.0  \n",
       "2          11080577.0  \n",
       "3          11080578.0  \n",
       "4          11080579.0  \n",
       "5          11080580.0  \n",
       "6          11080581.0  \n",
       "7          11080582.0  \n",
       "8          11080583.0  \n",
       "9          11080584.0  \n",
       "10         11080585.0  \n",
       "11         11080586.0  \n",
       "12         11080587.0  \n",
       "13         11080588.0  \n",
       "14         11080589.0  \n",
       "15         11080590.0  \n",
       "0          11080591.0  \n",
       "1          11080592.0  \n",
       "2          11080593.0  \n",
       "3          11080594.0  \n",
       "4          11080595.0  \n",
       "5          11080596.0  \n",
       "6          11080597.0  \n",
       "7          11080598.0  \n",
       "0          11080599.0  \n",
       "1          11080600.0  \n",
       "2          11080601.0  \n",
       "3          11080602.0  \n",
       "4          11080603.0  \n",
       "5          11080604.0  \n",
       "6          11080605.0  \n",
       "7          11080606.0  \n",
       "0          11080607.0  \n",
       "1          11080608.0  \n",
       "2          11080609.0  \n",
       "3          11080610.0  \n",
       "4          11080611.0  \n",
       "5          11080612.0  \n",
       "6          11080613.0  \n",
       "7          11080614.0  \n",
       "0          11080615.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "#fobj.filesize()\n",
    "print(len(block_hash_df))\n",
    "#fobj.filename()\n",
    "#fobj.byte_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7fd4a7347b30>\n"
     ]
    }
   ],
   "source": [
    "iterlist = (row for row in iters)\n",
    "print(iterlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist= [obj for obj in iters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for what in iterlist:\n",
    "    print(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPIpool.py\n",
    "\n",
    "from mpi4py.futures import MPIPoolExecutor\n",
    "import math\n",
    "import textwrap\n",
    "import hashlib\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pprint\n",
    "from pprint import pprint\n",
    "import dfxml \n",
    "\n",
    "def compute_hash(range_tuple):\n",
    "    img_path = '/home/oadegbeh/M57/pat-2009-12-10.raw.raw'\n",
    "    sector_hash_list = []\n",
    "    print(range_tuple[0], range_tuple[1])\n",
    "    sector_size = 512\n",
    "    img_h = open(img_path, 'rb')\n",
    "    for pointer in range(range_tuple[0], range_tuple[1]):\n",
    "                #print(pointer)\n",
    "                img_offset = pointer*sector_size\n",
    "                img_h.seek(img_offset)\n",
    "                fsector = img_h.read(sector_size)\n",
    "                sector_md5 = hashlib.md5(fsector).hexdigest()\n",
    "                sector_hash_list.append((img_offset,sector_md5))\n",
    "    return sector_hash_list\n",
    "\n",
    "def process_object_sectors(range_tuple):\n",
    "    sector_size = 512\n",
    "    img_csv = \"/Volumes/Samsung_T5/argo/pat2.csv\"\n",
    "    img_csv_df = pd.read_csv(img_csv)\n",
    "    global options\n",
    "    files_cols = ['obj_id', 'partition','inode','filename','filesize']\n",
    "    block_hashes_cols = ['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1']\n",
    "    file_df = pd.DataFrame(columns=files_cols)\n",
    "    ebyterun_df = pd.DataFrame(columns=block_hashes_cols)\n",
    "    return_list = []\n",
    "    for obj in range(range_tuple[0], range_tuple[1]):\n",
    "        # Filter out specific filenames create by TSK that are not of use\n",
    "        print(\"processing this  %s\" % str(obj))\n",
    "        print(type(obj))\n",
    "        #if int(obj._tags['id']) == id:# and obj.filesize() == False:\n",
    "        #counter += 1\n",
    "        #print(obj.filename())\n",
    "        data = [str(obj), obj.partition(),obj.inode(), obj.filename(),  obj.filesize()] #obj._tags['id']\n",
    "        file_df.loc[len(file_df.index)] = data\n",
    "        print(data)\n",
    "        byterun = []\n",
    "        persist_img_offset = 0\n",
    "        persist_fs_offset = 0\n",
    "        persist_file_offset = 0\n",
    "        remaining_len = obj.filesize()\n",
    "        #ebyterun_df = pd.DataFrame(columns=['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1'])\n",
    "        for ebyterun in obj.byte_runs():\n",
    "            #pprint(vars(ebyterun)) \n",
    "            #byterun.append([ebyterun.img_offset,ebyterun.file_offset, ebyterun.len, ebyterun.fs_offset])\n",
    "            byterun.append(ebyterun.file_offset)\n",
    "            persist_file_offset = ebyterun.file_offset\n",
    "            byterun.append(ebyterun.len)\n",
    "            if hasattr(ebyterun,'img_offset'): \n",
    "                byterun.append(ebyterun.img_offset)\n",
    "                if ebyterun.img_offset != None: persist_img_offset = ebyterun.img_offset\n",
    "            if hasattr(ebyterun,'fs_offset'): \n",
    "                byterun.append(ebyterun.fs_offset)\n",
    "                if ebyterun.fs_offset != None: persist_fs_offset = ebyterun.fs_offset\n",
    "            if hasattr(ebyterun,'len'): \n",
    "                byterun.append(ebyterun.len)\n",
    "                if ebyterun.len != None: persist_len = ebyterun.len\n",
    "            #print(\"img_offset\", img_offset, \"file offset\", ebyterun.file_offset)\n",
    "            #print(\"file_offset\", \"len\", \"img_offset\", \"fs_offset\")\n",
    "            byterun_start = int(persist_img_offset / sector_size)\n",
    "            byterun_end = int((math.ceil((persist_img_offset + ebyterun.len) / sector_size))) - 1\n",
    "            len_run = np.arange(persist_len,0,-sector_size) #remaining_len\n",
    "            sector_run = np.full(len(len_run), sector_size)\n",
    "            len_run = np.minimum(len_run,sector_run)\n",
    "            #len_run = min(sector_size,len_run.all())\n",
    "            #print(\"len_run\",len(len_run), len(len_run)*sector_size)\n",
    "            #print(\"byterun_start\", byterun_start,persist_img_offset, \"byterun_end\", byterun_end,  \"len\", ebyterun.len)\n",
    "            #print(\"ebyterun_df\", ebyterun_df.shape, \"img_csv\", img_csv_df.loc[byterun_start:byterun_end,'img_offset'].shape )\n",
    "            #print(img_csv_df.loc[byterun_start:byterun_end,:])\n",
    "            #print(\"img_csv_len\",len(img_csv_df.loc[byterun_start:byterun_end, :]))\n",
    "            ebyterun_df.loc[:,'img_sector_offset'] = np.arange(len(img_csv_df))\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'obj_id'] = str(obj) #obj._tags['id']\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'img_offset'] = img_csv_df.loc[byterun_start:byterun_end,'img_offset']\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'fs_offset'] = np.arange(persist_fs_offset,persist_fs_offset+ebyterun.len,sector_size)\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'file_offset'] = np.arange(persist_file_offset,persist_file_offset+ebyterun.len, sector_size)\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'len'] = len_run\n",
    "            #print(\"remaining_len\",remaining_len)\n",
    "            #remaining_len-=sector_size\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'md5'] = img_csv_df.loc[byterun_start:byterun_end,'md5']\n",
    "            return_list.append((file_df,ebyterun_df))\n",
    "        print(\"done processing %s\" % str(obj))\n",
    "    return return_list   \n",
    "\n",
    "def determine_subranges(fullrange, num_subranges):\n",
    "    \"\"\"\n",
    "    Break fullrange up into smaller sets of ranges that cover all\n",
    "    the same numbers.\n",
    "    \"\"\"\n",
    "    subranges = []\n",
    "    inc = fullrange[1] // num_subranges\n",
    "    for i in range(fullrange[0], fullrange[1], inc):\n",
    "        subranges.append( (i, min(i+inc, fullrange[1])) )\n",
    "    return( subranges )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #sector_size = 512\n",
    "    img_path = '/Volumes/Samsung_T5/M57/pat-2009-12-10.raw.xml'\n",
    "    object_number = dfxml.iter_dfxml(img_path, preserve_elements=True)\n",
    "    img_objcount = len(list(object_number))\n",
    "    fullrange = (0, img_objcount)\n",
    "    num_subranges = 1000\n",
    "    subranges = determine_subranges(fullrange, num_subranges)\n",
    "\n",
    "    executor = MPIPoolExecutor()\n",
    "    sectors_df_list = executor.map(process_object_sectors, subranges)\n",
    "    #files_df_list = executor.map(process_object_files, subranges)\n",
    "    executor.shutdown()\n",
    "    grand_sectors_df = pd.DataFrame()\n",
    "    grand_files_df = pd.DataFrame()\n",
    "    # flatten the list of lists\n",
    "    for df in sectors_df_list:\n",
    "        grand_files_df = pd.concat([grand_files_df, df[0]])\n",
    "        grand_sectors_df = pd.concat([grand_sectors_df, df[1]])\n",
    "    #for df in files_df_list:\n",
    "    #    grand_files_df = pd.concat([grand_files_df, df])\n",
    "    #print(textwrap.fill(str(primes),80))\n",
    "    con = sqlite3.connect(\"/Volumes/Samsung_T5/M57/pat.db\")\n",
    "    grand_sectors_df.to_sql('block_hashes', con, index=True)\n",
    "    grand_files_df.to_sql('files', con, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LATEST VERSION\n",
    "# MPIpool.py\n",
    "\n",
    "from mpi4py.futures import MPIPoolExecutor\n",
    "import math\n",
    "import textwrap\n",
    "import hashlib\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "#import sqlite3\n",
    "import numpy as np\n",
    "import pprint\n",
    "from pprint import pprint\n",
    "import dfxml \n",
    "\n",
    "def compute_hash(range_tuple):\n",
    "    img_path = '/home/oadegbeh/M57/pat-2009-12-10.raw.raw'\n",
    "    sector_hash_list = []\n",
    "    print(range_tuple[0], range_tuple[1])\n",
    "    sector_size = 512\n",
    "    img_h = open(img_path, 'rb')\n",
    "    for pointer in range(range_tuple[0], range_tuple[1]):\n",
    "                #print(pointer)\n",
    "                img_offset = pointer*sector_size\n",
    "                img_h.seek(img_offset)\n",
    "                fsector = img_h.read(sector_size)\n",
    "                sector_md5 = hashlib.md5(fsector).hexdigest()\n",
    "                sector_hash_list.append((img_offset,sector_md5))\n",
    "    return sector_hash_list\n",
    "\n",
    "def process_object_sectors(objlist):\n",
    "    sector_size = 512\n",
    "    img_csv = \"/home/oadegbeh/M57/pat2.csv\"\n",
    "    img_csv_df = pd.read_csv(img_csv)\n",
    "    global options\n",
    "    files_cols = ['obj_id', 'partition','inode','filename','filesize']\n",
    "    block_hashes_cols = ['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1']\n",
    "    file_df = pd.DataFrame(columns=files_cols)\n",
    "    ebyterun_df = pd.DataFrame(columns=block_hashes_cols)\n",
    "    return_list = []\n",
    "    for obj in objlist:#range(range_tuple[0], range_tuple[1]):\n",
    "        # Filter out specific filenames create by TSK that are not of use\n",
    "        print(\"processing %s\" % obj._tags['id']) #str(obj)\n",
    "        #print(type(obj))\n",
    "        #if int(obj._tags['id']) == id:# and obj.filesize() == False:\n",
    "        #counter += 1\n",
    "        #print(obj.filename())\n",
    "        data = [obj._tags['id'], obj.partition(),obj.inode(), obj.filename(),  obj.filesize()] #\n",
    "        file_df.loc[len(file_df.index)] = data\n",
    "        print(data)\n",
    "        byterun = []\n",
    "        persist_img_offset = 0\n",
    "        persist_fs_offset = 0\n",
    "        persist_file_offset = 0\n",
    "        remaining_len = obj.filesize()\n",
    "        #ebyterun_df = pd.DataFrame(columns=['obj_id','img_offset','fs_offset','file_offset','len','md5','sha1'])\n",
    "        for ebyterun in obj.byte_runs():\n",
    "            #pprint(vars(ebyterun)) \n",
    "            #byterun.append([ebyterun.img_offset,ebyterun.file_offset, ebyterun.len, ebyterun.fs_offset])\n",
    "            byterun.append(ebyterun.file_offset)\n",
    "            persist_file_offset = ebyterun.file_offset\n",
    "            byterun.append(ebyterun.len)\n",
    "            if hasattr(ebyterun,'img_offset'): \n",
    "                byterun.append(ebyterun.img_offset)\n",
    "                if ebyterun.img_offset != None: persist_img_offset = ebyterun.img_offset\n",
    "            if hasattr(ebyterun,'fs_offset'): \n",
    "                byterun.append(ebyterun.fs_offset)\n",
    "                if ebyterun.fs_offset != None: persist_fs_offset = ebyterun.fs_offset\n",
    "            if hasattr(ebyterun,'len'): \n",
    "                byterun.append(ebyterun.len)\n",
    "                if ebyterun.len != None: persislen = ebyterun.len\n",
    "            #print(\"img_offset\", img_offset, \"file offset\", ebyterun.file_offset)\n",
    "            #print(\"file_offset\", \"len\", \"img_offset\", \"fs_offset\")\n",
    "            byterun_start = int(persist_img_offset / sector_size)\n",
    "            byterun_end = int((math.ceil((persist_img_offset + ebyterun.len) / sector_size))) - 1\n",
    "            len_run = np.arange(persist_len,0,-sector_size) #remaining_len\n",
    "            sector_run = np.full(len(len_run), sector_size)\n",
    "            len_run = np.minimum(len_run,sector_run)\n",
    "            #len_run = min(sector_size,len_run.all())\n",
    "            #print(\"len_run\",len(len_run), len(len_run)*sector_size)\n",
    "            #print(\"byterun_start\", byterun_start,persist_img_offset, \"byterun_end\", byterun_end,  \"len\", ebyterun.len)\n",
    "            #print(\"ebyterun_df\", ebyterun_df.shape, \"img_csv\", img_csv_df.loc[byterun_start:byterun_end,'img_offset'].shape )\n",
    "            #print(img_csv_df.loc[byterun_start:byterun_end,:])\n",
    "            #print(\"img_csv_len\",len(img_csv_df.loc[byterun_start:byterun_end, :]))\n",
    "            ebyterun_df.loc[:,'img_sector_offset'] = np.arange(len(img_csv_df))\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'obj_id'] = str(obj) #obj._tags['id']\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'img_offset'] = img_csv_df.loc[byterun_start:byterun_end,'img_offset']\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'fs_offset'] = np.arange(persist_fs_offset,persist_fs_offset+ebyterun.len,sector_size)\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'file_offset'] = np.arange(persist_file_offset,persist_file_offset+ebyterun.len, sector_size)\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'len'] = len_run\n",
    "            #print(\"remaining_len\",remaining_len)\n",
    "            #remaining_len-=sector_size\n",
    "            ebyterun_df.loc[byterun_start:byterun_end,'md5'] = img_csv_df.loc[byterun_start:byterun_end,'md5']\n",
    "            return_list.append((file_df,ebyterun_df))\n",
    "        print(\"done processing %s\" % obj._tags['id']) #str(obj)\n",
    "    return return_list   \n",
    "\n",
    "def determine_subranges(obj_list, num_subranges):#fullrange\n",
    "    \"\"\"\n",
    "    Break fullrange up into smaller sets of ranges that cover all\n",
    "    the same numbers.\n",
    "    \"\"\"\n",
    "    subranges = []\n",
    "    inc =  len(obj_list)// num_subranges #fullrange[1]\n",
    "    for i in range(0, len(obj_list), inc):#fullrange[0], fullrange[1]\n",
    "        subranges.append( (obj_list[i], obj_list[min(i+inc,len(obj_list)-1 )]) )#fullrange[1]\n",
    "    return( subranges )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #sector_size = 512\n",
    "    img_path = '/home/oadegbeh/M57/pat-2009-12-10.raw.xml'\n",
    "    object_gen = dfxml.iter_dfxml(img_path, preserve_elements=True)\n",
    "    obj_list = []\n",
    "    for each_obj in object_gen:\n",
    "        obj_list.append(each_obj)\n",
    "    #img_objcount = len(obj_list)\n",
    "    #fullrange = (0, img_objcount)\n",
    "    num_subranges = 1000\n",
    "    subranges = determine_subranges(obj_list, num_subranges)#fullrange\n",
    "\n",
    "    executor = MPIPoolExecutor()\n",
    "    sectors_df_list = executor.map(process_object_sectors, subranges)\n",
    "    #files_df_list = executor.map(process_object_files, subranges)\n",
    "    executor.shutdown()\n",
    "    grand_sectors_df = pd.DataFrame()\n",
    "    grand_files_df = pd.DataFrame()\n",
    "    # flatten the list of lists\n",
    "    for df in sectors_df_list: #COULD THIS BE A PROBLEM POINT?\n",
    "        grand_files_df = pd.concat([grand_files_df, df[0]])\n",
    "        grand_sectors_df = pd.concat([grand_sectors_df, df[1]])\n",
    "    #for df in files_df_list:\n",
    "    #    grand_files_df = pd.concat([grand_files_df, df])\n",
    "    #print(textwrap.fill(str(primes),80))\n",
    "    con = sqlite3.connect(\"/scratch/oadegbeh/pat.db\")\n",
    "    grand_sectors_df.to_sql('block_hashes', con, index=True)\n",
    "    grand_files_df.to_sql('files', con, index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('scan_match_validate_all_mpi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9897bb9d3ea6b47cb59a3fa29a33cee83df786d8baa248772bb7eb2ce311867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
