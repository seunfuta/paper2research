{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: python3 jones_scan_match_2.py /Volumes/Samsung_T5/Research/JSON/LastProj/ /Volumes/Samsung_T5/Research/IMGCSV/512-Python264-WinXP-BIOC.csv\n",
    "# import fiwalk\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "# import dfxml\n",
    "import json\n",
    "import argparse\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import sqlite3\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "from time import process_time\n",
    "from time import time, strftime, localtime\n",
    "from datetime import timedelta\n",
    "# pd.set_option('display.max_columns', None)\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "SECTOR_SIZE = 512\n",
    "SECTORS_PER_CLUSTER = 8\n",
    "\n",
    "diskprint_dict = {\n",
    "        '9480-2-14416-1': 'Wireshark-W7x64',\n",
    "        '9480-1-14417-1': 'Wireshark-W7x32',\n",
    "        '9480-1-14782-1': 'Winzip17pro-W7x32',\n",
    "        '9480-2-14782-1': 'Winzip17pro-W7x64',\n",
    "        '9480-1-15142-1': 'sdelete-W7x32',\n",
    "        '9480-2-15142-1': 'sdelete-W7x64',\n",
    "        '234-1-14351-1': 'OfficePro2003-WinXP',\n",
    "        '9480-2-14351-1': 'OfficePro2003-W7x64',\n",
    "        '9480-1-14351-1': 'OfficePro2003-W7x32',\n",
    "        '9480-1-15149-1': 'Winrar5beta-W7x32',\n",
    "        '234-1-14887-1': 'Firefox19-WinXP',\n",
    "        '9480-2-15149-1': 'Winrar5beta-W7x64',\n",
    "        '9480-1-14887-1': 'Firefox19-W7x32',\n",
    "        '9480-1-15150-1': 'HxD171-W7x32',\n",
    "        '9480-2-14887-1': 'Firefox19-W7x64',\n",
    "        '234-1-7959-1': 'Thunderbird2-WinXP',\n",
    "        '234-1-15487-1': 'Python264-WinXP',\n",
    "        '9480-1-15146-1': 'eraser-W7x32',\n",
    "        '9480-2-15137-1': 'Chrome28-W7x64',\n",
    "        '234-1-15137-1': 'Chrome28-WinXP',\n",
    "        '9480-1-15137-1': 'Chrome28-W7x32',\n",
    "        '9480-1-15151-1': 'Safari157-W7x32',\n",
    "        '234-1-15151-1': 'Safari157-WinXP',\n",
    "        '9480-2-15151-1': 'Safari157-W7x64',\n",
    "        '234-1-15488-1': 'TrueCrypt63-WinXP',\n",
    "        '234-1-15485-1': 'AdvancedKeylogger-WinXP',\n",
    "        '234-1-15489-1': 'InvisibleSecrets21-WinXP',\n",
    "        '9480-1-15141-1': 'UPX-W7x32',\n",
    "        '9480-2-15141-1': 'UPX-W7x64'\n",
    "    }\n",
    "app2diskprint_dict = {\n",
    "    'Wireshark-W7x64': '9480-2-14416-1',\n",
    "    'Wireshark-W7x32': '9480-1-14417-1',\n",
    "    'Winzip17pro-W7x32': '9480-1-14782-1',\n",
    "    'Winzip17pro-W7x64': '9480-2-14782-1',\n",
    "    'sdelete-W7x32': '9480-1-15142-1',\n",
    "    'sdelete-W7x64': '9480-2-15142-1',\n",
    "    'OfficePro2003-WinXP': '234-1-14351-1',\n",
    "    'OfficePro2003-W7x64': '9480-2-14351-1',\n",
    "    'OfficePro2003-W7x32': '9480-1-14351-1',\n",
    "    'Winrar5beta-W7x32': '9480-1-15149-1',\n",
    "    'Firefox19-WinXP': '234-1-14887-1',\n",
    "    'Winrar5beta-W7x64': '9480-2-15149-1',\n",
    "    'Firefox19-W7x32': '9480-1-14887-1',\n",
    "    'HxD171-W7x32': '9480-1-15150-1',\n",
    "    'Firefox19-W7x64': '9480-2-14887-1',\n",
    "    'Thunderbird2-WinXP': '234-1-7959-1',\n",
    "    'Python264-WinXP': '234-1-15487-1',\n",
    "    'eraser-W7x32': '9480-1-15146-1',\n",
    "    'Chrome28-W7x64': '9480-2-15137-1',\n",
    "    'Chrome28-WinXP': '234-1-15137-1',\n",
    "    'Chrome28-W7x32': '9480-1-15137-1',\n",
    "    'Safari157-W7x32': '9480-1-15151-1',\n",
    "    'Safari157-WinXP': '234-1-15151-1',\n",
    "    'Safari157-W7x64': '9480-2-15151-1',\n",
    "    'TrueCrypt63-WinXP': '234-1-15488-1',\n",
    "    'AdvancedKeylogger-WinXP': '234-1-15485-1',\n",
    "    'InvisibleSecrets21-WinXP': '234-1-15489-1',\n",
    "    'UPX-W7x32': '9480-1-15141-1',\n",
    "    'UPX-W7x64': '9480-2-15141-1'\n",
    "}\n",
    "'''\n",
    "parser = argparse.ArgumentParser(description='This is an image scanning program based on Jones\\'s approach')\n",
    "parser.add_argument('-i', action=\"store\", dest=\"i\", help='image (DB)', default='/Users/seunfuta/Downloads/NIST/DECAYED/3WSharks-decay25b.db') #image\n",
    "parser.add_argument('-c', action=\"store\", dest=\"c\", help='catalog (DB)', default='/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db') #catalog\n",
    "#parser.add_argument('-a', action=\"store\", dest=\"a\", help='application name  e.g. \\\n",
    "                #Wireshark-W7x64, Wireshark-W7x32, Winzip17pro-W7x32, Winzip17pro-W7x64,\\\n",
    "                #sdelete-W7x32, sdelete-W7x64, OfficePro2003-WinXP, OfficePro2003-W7x64,\\\n",
    "                #OfficePro2003-W7x32, Winrar5beta-W7x32, Firefox19-WinXP, Winrar5beta-W7x64,\\\n",
    "                #Firefox19-W7x32, HxD171-W7x32, Firefox19-W7x64, Thunderbird2-WinXP, \\\n",
    "                #Python264-WinXP, eraser-W7x32, Chrome28-W7x64, Chrome28-WinXP, Chrome28-W7x32,\\\n",
    "                #Safari157-W7x32, Safari157-WinXP, Safari157-W7x64, TrueCrypt63-WinXP, \\\n",
    "                #AdvancedKeylogger-WinXP, InvisibleSecrets21-WinXP, UPX-W7x32,UPX-W7x64', default='Wireshark-W7x64')\n",
    "parser.add_argument('-o', action=\"store\", dest=\"o\", help='updated output image(DB)', default='/Users/seunfuta/Downloads/NIST/SCANNED/3WSharks-decay25b-Jscanned.db') #image\n",
    "parser.add_argument('-ocsv', action=\"store\", dest=\"ocsv\", help='output result (CSV)', default='/Users/seunfuta/Downloads/NIST/SCANRESULT/3WSharks-decay25b-Jscanned.csv') #image\n",
    "'''\n",
    "\n",
    "'''wireshark, winzip, sdelete, office, winrar, \n",
    "firefox, chrome, safari, hxd, thunderbird, \n",
    "python, eraser, truecrypt, advancedkeylogger, \n",
    "invisiblesecrets, upx ') #app\n",
    "'''\n",
    "\n",
    "#result = parser.parse_args()\n",
    "\n",
    "def get_image_df(image_path):\n",
    "    img_filepath = image_path\n",
    "    img_sqlconn = sqlite3.connect(img_filepath)\n",
    "    img_sectors_df = pd.DataFrame()\n",
    "    img_sectors_df = pd.DataFrame(columns=['obj_id','file_offset','len','md5','sha1' ,'partition','inode','filename','filesize'])\n",
    "    img_sectors_df = pd.read_sql_query(\"SELECT * FROM files INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id;\", img_sqlconn)\n",
    "    #block_hashes[obj_id,file_offset,len,md5,sha1,*decay], files[partition,inode,filename,filesize,*actual-APP]\n",
    "    img_sectors_df = img_sectors_df[img_sectors_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    img_sectors_df = img_sectors_df[img_sectors_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    img_sectors_df = img_sectors_df[img_sectors_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    img_sectors_df = img_sectors_df[img_sectors_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "    img_sqlconn.close()\n",
    "    print(\"image length, \", len(img_sectors_df))\n",
    "    return img_sectors_df\n",
    "'''\n",
    "def get_hashfreq_dict(catalog_path):\n",
    "    catalog_filepath = catalog_path\n",
    "    catalog_sqlconn = sqlite3.connect(catalog_filepath)\n",
    "    appdf = pd.DataFrame(columns=['md5', 'file_offset', 'obj_id', 'filename', 'filesize'])\n",
    "    appdf = pd.read_sql_query(\"SELECT block_hashes.md5, block_hashes.file_offset, files.obj_id, files.filename, files.filesize \\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.app is '\" + key + \"';\", catalog_sqlconn)\n",
    "    appdf = appdf[appdf.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    appdf = appdf[appdf.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    appdf = appdf[appdf.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    appdf = appdf[appdf.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "\n",
    "    catalog_sqlconn.close()\n",
    "\n",
    "    hashfreq_dict = {}\n",
    "\n",
    "    return hashfreq_dict\n",
    "'''\n",
    "def get_app_df(catalog_path, key):\n",
    "    catalog_filepath = catalog_path\n",
    "    catalog_sqlconn = sqlite3.connect(catalog_filepath)\n",
    "    appdf = pd.DataFrame(columns=['md5', 'file_offset', 'obj_id', 'filename', 'filesize'])\n",
    "    appdf = pd.read_sql_query(\"SELECT block_hashes.md5, block_hashes.file_offset, files.obj_id, files.filename, files.filesize \\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.app is '\" + key + \"';\", catalog_sqlconn)\n",
    "    appdf = appdf[appdf.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    appdf = appdf[appdf.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    appdf = appdf[appdf.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    appdf = appdf[appdf.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "\n",
    "    catalog_sqlconn.close()\n",
    "    print(\"catalog app length, \", len(appdf))\n",
    "    return appdf\n",
    "\n",
    "def get_key_list(catalog_path):\n",
    "    catalog_filepath = catalog_path\n",
    "    catalog_sqlconn = sqlite3.connect(catalog_filepath)\n",
    "    appdf = pd.DataFrame(columns=['md5', 'file_offset', 'obj_id', 'filename', 'filesize'])\n",
    "    key_list_df = pd.read_sql_query(\"SELECT DISTINCT app FROM files;\", catalog_sqlconn)\n",
    "    #appdf = appdf[appdf.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    #appdf = appdf[appdf.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    #catalog_sqlconn.close()\n",
    "    #print(\"catalog app length, \", len(appdf))\n",
    "    return key_list_df['app'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image length,  586972\n",
      "original length  6826014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time()\n",
    "    jones_df = pd.DataFrame()\n",
    "        #columns=['Appname', 'tn', 'fp', 'fn', 'tp', 'accuracy', 'recall_0', 'recall_1', 'precision_0', 'precision_1',\n",
    "                 #'f1_0', 'f1_1', 'image_size'])\n",
    "    '''\n",
    "    os_df = pd.read_csv(\"/Users/seunfuta/Downloads/NIST/NISToscatalog.csv\")\n",
    "    os_df.rename(columns={'md5': 'block_hash'}, inplace=True)\n",
    "    os_uniqhash_df = pd.DataFrame(os_df.block_hash.value_counts()).reset_index()\n",
    "    os_uniqhash_df.columns = ['block_hash', 'freq']\n",
    "    '''\n",
    "    resultc=\"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "    resulti=\"/Users/seunfuta/Downloads/NIST/IMG/Wireshark-W7x32.db\"\n",
    "    resulto=\"/Users/seunfuta/Downloads/NIST/OLUSCAN/\"\n",
    "    #for app_number in range(0, len(diskprint_dict)):\n",
    "    imgdf = pd.DataFrame()\n",
    "    # input  = sys.argv[1]\n",
    "    #key_list = app2diskprint_dict.app.unique() #app2diskprint_dict[result.a]\n",
    "    result_df = pd.DataFrame(columns=['appname','appsize', 'actual','matches','P(app)'])\n",
    "\n",
    "    imgdf = get_image_df(resulti)\n",
    "    #### new\n",
    "    #hash_freq_dict = get_hashfreq_dict(result.c)\n",
    "    catalog_filepath = resultc\n",
    "    catalog_sqlconn = sqlite3.connect(catalog_filepath)\n",
    "    catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "    catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                    block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                    FROM files \\\n",
    "                    INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                    and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_sqlconn)\n",
    "    print(\"original length \",len(catalog_df))\n",
    "    catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "\n",
    "    catalog_sqlconn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ### end new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wireshark-W7x64', 'Wireshark-W7x32', 'Winzip17pro-W7x32',\n",
       "       'Winzip17pro-W7x64', 'sdelete-W7x32', 'sdelete-W7x64',\n",
       "       'OfficePro2003-WinXP', 'OfficePro2003-W7x64',\n",
       "       'OfficePro2003-W7x32', 'Winrar5beta-W7x32', 'Firefox19-WinXP',\n",
       "       'Winrar5beta-W7x64', 'Firefox19-W7x32', 'HxD171-W7x32',\n",
       "       'Firefox19-W7x64', 'Thunderbird2-WinXP', 'Python264-WinXP',\n",
       "       'eraser-W7x32', 'Chrome28-W7x64', 'Chrome28-WinXP',\n",
       "       'Chrome28-W7x32', 'Safari157-W7x32', 'Safari157-WinXP',\n",
       "       'Safari157-W7x64', 'TrueCrypt63-WinXP', 'AdvancedKeylogger-WinXP',\n",
       "       'InvisibleSecrets21-WinXP', 'UPX-W7x32', 'UPX-W7x64'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_list = catalog_df.app.unique()\n",
    "key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list = catalog_df.app.unique()\n",
    "global_md5_series = pd.Series()\n",
    "for each_app in app_list:\n",
    "    appdf = catalog_df[catalog_df.app == each_app]\n",
    "    each_apphash_list = appdf.md5.unique()\n",
    "    global_md5_series = global_md5_series.append(pd.Series(each_apphash_list), ignore_index=True)\n",
    "global_md5_series_freq_map = global_md5_series.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(key_list)\n",
    "#key_list.index('Wireshark-W7x64')\n",
    "#key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog app length,  363488\n",
      "appname Chrome28-WinXP\n",
      "appsize 363488\n"
     ]
    }
   ],
   "source": [
    "#for key in key_list:\n",
    "key = 'Chrome28-WinXP'\n",
    "appdf = get_app_df(resultc, key)\n",
    "result_df.loc[key_list.index(key), 'appname'] = key\n",
    "print(\"appname\",key)\n",
    "result_df.loc[key_list.index(key),'appsize'] = len(appdf)\n",
    "print(\"appsize\",len(appdf))\n",
    "imgdf = imgdf.loc[:, ~imgdf.columns.duplicated()] #this removes duplicate columns ref https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\n",
    "# next step is to label the imgdf with the actual-app\n",
    "\n",
    "# get the short list of obj_id (that belongs to the app you are testing) in the\n",
    "app_file_filenames = appdf.filename.unique()  # type np.ndarray\n",
    "if str('actual-' + key) not in imgdf.columns:\n",
    "    imgdf[\"actual-\" + key] = np.where(imgdf.filename.isin(app_file_filenames), 1, 0)\n",
    "#print(imgdf[\"actual-\" + diskprint_dict[key]].value_counts())\n",
    "\n",
    "#### get all unique block_hashes\n",
    "app_uniquemd5s = appdf.md5.unique()\n",
    "imgdf[\"predict-\" + key] = np.where(imgdf.md5.isin(app_uniquemd5s), 1, 0)\n",
    "if 'decay' in imgdf.columns:\n",
    "    imgdf.loc[imgdf.decay == 1,\"predict-\" + key] = 0 #if decay is set, your prediction should be null, didn't work\n",
    "    imgdf.loc[imgdf.decay == 1, \"actual-\" + key] = 0\n",
    "else:\n",
    "    imgdf = imgdf.assign(decay = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdf['freq'] = imgdf.md5.map(global_md5_series_freq_map)\n",
    "\n",
    "imgdf['inv_freq'] = 1/imgdf['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual 0\n",
      "actual_uniq 0.0\n",
      "matches 80\n",
      "matches_uniq 63.0\n",
      "freq_matches 17.044696969696968\n",
      "freq_matches_uniq 13.497727272727271\n",
      "P(app) 0.00022\n",
      "P(app)new 5e-05\n",
      "appsize 363488\n",
      "appsize_uniq 270779.0\n",
      "P(app)new_uniq 4e-05\n"
     ]
    }
   ],
   "source": [
    "result_df.loc[key_list.index(key), 'actual'] = len(imgdf[imgdf[\"actual-\" + key]==1])\n",
    "print(\"actual\", result_df.loc[key_list.index(key), 'actual'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'actual_uniq'] = len(imgdf[imgdf[\"actual-\" + key]==1].drop_duplicates(subset='md5', keep='first'))\n",
    "print(\"actual_uniq\", result_df.loc[key_list.index(key), 'actual_uniq'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'matches'] = len(imgdf[imgdf[\"predict-\" + key]==1])\n",
    "print(\"matches\",result_df.loc[key_list.index(key), 'matches'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'matches_uniq'] = len(imgdf[imgdf[\"predict-\" + key]==1].drop_duplicates(subset='md5', keep='first'))\n",
    "print(\"matches_uniq\", result_df.loc[key_list.index(key), 'matches_uniq'])\n",
    "\n",
    "#result_df.loc[key_list.index(key), 'freq_matches'] = imgdf['inv_freq'].sum()\n",
    "imgdf['inv_freq'] = imgdf['inv_freq'].multiply(imgdf[\"predict-\" + key], fill_value=0)\n",
    "result_df.loc[key_list.index(key), 'freq_matches'] = imgdf['inv_freq'].sum()\n",
    "print(\"freq_matches\",result_df.loc[key_list.index(key), 'freq_matches'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'freq_matches_uniq'] = imgdf.drop_duplicates(subset='md5', keep='first')['inv_freq'].sum()\n",
    "print(\"freq_matches_uniq\",result_df.loc[key_list.index(key), 'freq_matches_uniq'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'P(app)'] = round(float(result_df.loc[key_list.index(key), 'matches'])/float(result_df.loc[key_list.index(key), 'appsize']),5)\n",
    "print(\"P(app)\", result_df.loc[key_list.index(key), 'P(app)'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'P(app)new'] = round(float(result_df.loc[key_list.index(key), 'freq_matches'])/float(result_df.loc[key_list.index(key), 'appsize']),5)\n",
    "print(\"P(app)new\", result_df.loc[key_list.index(key), 'P(app)new'])\n",
    "\n",
    "result_df.loc[key_list.index(key),'appsize_uniq'] = len(appdf.drop_duplicates(subset='md5', keep='first'))\n",
    "print(\"appsize\",len(appdf))\n",
    "print(\"appsize_uniq\",result_df.loc[key_list.index(key),'appsize_uniq'])\n",
    "\n",
    "result_df.loc[key_list.index(key), 'P(app)new_uniq'] = round(float(result_df.loc[key_list.index(key), 'freq_matches_uniq'])/float(result_df.loc[key_list.index(key), 'appsize']),5)\n",
    "print(\"P(app)new_uniq\", result_df.loc[key_list.index(key), 'P(app)new_uniq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171570\n",
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.044696969696968"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imgdf['inv_freq'].dropna():\n",
    "print(len(imgdf[imgdf['inv_freq'].notna()]))\n",
    "print(len(imgdf[imgdf[\"predict-\" + key]==1]))\n",
    "#imgdf[imgdf[\"predict-\" + key]==1].to_clipboard()\n",
    "#result_df.loc[key_list.index(key), 'freq_matches'] = imgdf['inv_freq'].sum()\n",
    "#print(\"freq_matches\",result_df.loc[key_list.index(key), 'freq_matches'])\n",
    "imgdf['inv_freq'].sum()\n",
    "imgdf['new_inv_freq'] = imgdf['inv_freq'].multiply(imgdf[\"predict-\" + key], fill_value=0)\n",
    "imgdf['new_inv_freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "what = len(imgdf[imgdf[\"predict-\" + key]==1].drop_duplicates(subset='md5', keep='first'))\n",
    "print(what)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1895fe77d861caeaa821f2df72086efbb9754c9ce180e62170f24c0ec4bbaef9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('paper2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
