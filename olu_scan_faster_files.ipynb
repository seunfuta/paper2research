{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length  6826014\n",
      "catalog app length,  6546710\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "CATALOG_DB_PATH = \"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "catalog_conn = sqlite3.connect(CATALOG_DB_PATH)\n",
    "catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_conn)\n",
    "print(\"original length \",len(catalog_df))\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "catalog_conn.close()\n",
    "print(\"catalog app length, \", len(catalog_df))\n",
    "#return appdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DB_PATH = \"/Volumes/Samsung_T5/M57/pat2.db\"\n",
    "image_conn = sqlite3.connect(IMAGE_DB_PATH)\n",
    "image_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize'])\n",
    "image_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, files.inode, files.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize \\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id;\", image_conn)\n",
    "print(\"original image length \",len(image_df))\n",
    "image_df = image_df[image_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "image_df = image_df[image_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "image_df = image_df[image_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "image_df = image_df[image_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "print(\"current image length \",len(image_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wireshark-W7x64  matched  56416  set  668  Prob  0.7266280078363769\n",
      "Wireshark-W7x32  matched  171330  set  671  Prob  0.7749653327951231\n",
      "Winzip17pro-W7x32  matched  184  set  172  Prob  0.12059453624616505\n",
      "Winzip17pro-W7x64  matched  95  set  175  Prob  0.10773653630243897\n",
      "sdelete-W7x32  matched  8  set  5  Prob  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/d__51l693s13d_yt81j0qp9r0000gn/T/ipykernel_1589/856091223.py:42: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdelete-W7x64  matched  0  set  3  Prob  0.0\n",
      "OfficePro2003-WinXP  matched  100  set  3348  Prob  0.0012685240430631059\n",
      "OfficePro2003-W7x64  matched  143  set  3235  Prob  0.0012901287958443266\n",
      "OfficePro2003-W7x32  matched  374  set  3233  Prob  0.0028759939977775063\n",
      "Winrar5beta-W7x32  matched  39  set  47  Prob  0.06433600269408653\n",
      "Firefox19-WinXP  matched  208  set  109  Prob  0.04656526247325898\n",
      "Winrar5beta-W7x64  matched  39  set  47  Prob  0.06433600269408653\n",
      "Firefox19-W7x32  matched  281  set  109  Prob  0.046077415564025996\n",
      "HxD171-W7x32  matched  27  set  15  Prob  0.0\n",
      "Firefox19-W7x64  matched  239  set  207  Prob  0.024399156938137077\n",
      "Thunderbird2-WinXP  matched  16  set  208  Prob  0.008685412908549057\n",
      "Python264-WinXP  matched  19  set  3014  Prob  0.0009684208827548923\n",
      "eraser-W7x32  matched  51  set  21  Prob  0.0\n",
      "Chrome28-W7x64  matched  207  set  1005  Prob  0.007346392643379124\n",
      "Chrome28-WinXP  matched  80  set  912  Prob  0.006906211286125168\n",
      "Chrome28-W7x32  matched  283  set  1004  Prob  0.007673822320699163\n",
      "Safari157-W7x32  matched  236  set  1317  Prob  0.06503655405562606\n",
      "Safari157-WinXP  matched  119  set  1288  Prob  0.06704651823611271\n",
      "Safari157-W7x64  matched  155  set  1298  Prob  0.06973199184972087\n",
      "TrueCrypt63-WinXP  matched  10  set  16  Prob  0.25920819195344935\n",
      "AdvancedKeylogger-WinXP  matched  0  set  30  Prob  0.0\n",
      "InvisibleSecrets21-WinXP  matched  0  set  25  Prob  0.0\n",
      "UPX-W7x32  matched  26  set  14  Prob  0.0\n",
      "UPX-W7x64  matched  26  set  14  Prob  0.0\n",
      "                           matched      prob\n",
      "Wireshark-W7x64            56416.0  0.726628\n",
      "Wireshark-W7x32           171330.0  0.774965\n",
      "Winzip17pro-W7x32            184.0  0.120595\n",
      "Winzip17pro-W7x64             95.0  0.107737\n",
      "sdelete-W7x32                  8.0  0.000000\n",
      "sdelete-W7x64                  0.0  0.000000\n",
      "OfficePro2003-WinXP          100.0  0.001269\n",
      "OfficePro2003-W7x64          143.0  0.001290\n",
      "OfficePro2003-W7x32          374.0  0.002876\n",
      "Winrar5beta-W7x32             39.0  0.064336\n",
      "Firefox19-WinXP              208.0  0.046565\n",
      "Winrar5beta-W7x64             39.0  0.064336\n",
      "Firefox19-W7x32              281.0  0.046077\n",
      "HxD171-W7x32                  27.0  0.000000\n",
      "Firefox19-W7x64              239.0  0.024399\n",
      "Thunderbird2-WinXP            16.0  0.008685\n",
      "Python264-WinXP               19.0  0.000968\n",
      "eraser-W7x32                  51.0  0.000000\n",
      "Chrome28-W7x64               207.0  0.007346\n",
      "Chrome28-WinXP                80.0  0.006906\n",
      "Chrome28-W7x32               283.0  0.007674\n",
      "Safari157-W7x32              236.0  0.065037\n",
      "Safari157-WinXP              119.0  0.067047\n",
      "Safari157-W7x64              155.0  0.069732\n",
      "TrueCrypt63-WinXP             10.0  0.259208\n",
      "AdvancedKeylogger-WinXP        0.0  0.000000\n",
      "InvisibleSecrets21-WinXP       0.0  0.000000\n",
      "UPX-W7x32                     26.0  0.000000\n",
      "UPX-W7x64                     26.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "app_list = catalog_df.app.unique()\n",
    "result_df = pd.DataFrame()\n",
    "for app in app_list:\n",
    "    #if app == 'OfficePro2003-W7x32':\n",
    "    app_df = catalog_df[catalog_df.app == app]\n",
    "    app_unique_md5s= app_df.md5.unique()\n",
    "    matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "    #print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "    #print(matched_image_df)\n",
    "    #lets create app sec pairs\n",
    "    app_files = app_df.filename.unique()\n",
    "    #print(app_files)\n",
    "    app_pairs_set = {} #dict #set() \n",
    "    for file in app_files:\n",
    "        file_hashpair_set = set()\n",
    "        files_df = app_df[app_df.filename == file]\n",
    "        #print(f'file {file} is of size {len(files_df)}')\n",
    "        file_hashes = files_df.md5\n",
    "        if len(file_hashes)< 2:\n",
    "            #print(file_hashes.iloc[0])\n",
    "            file_hashpair_set.add(file_hashes.iloc[0])\n",
    "        else:\n",
    "            for i in range(0, len(file_hashes)-1):\n",
    "                #print(file_hashes.iloc[i])\n",
    "                #print(file_hashes.iloc[int(i+1)])\n",
    "                hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "            #print(i, hash_pair)\n",
    "                file_hashpair_set.add(hash_pair)\n",
    "        app_pairs_set[file] = file_hashpair_set \n",
    "    #print(f\"set size is {len(app_pairs_set)}\")\n",
    "    lst2 = list(matched_image_df.md5)\n",
    "    lst2_pairs = list(map(lambda a, b: a + b, lst2[:-1], lst2[1:]))\n",
    "    Prob_Total = 0\n",
    "    for file in app_files:\n",
    "        #x = 0 #setting a default value\n",
    "        forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "        x= forward_list.count(1)\n",
    "        t= len(forward_list)+0.0000000001\n",
    "        s = 1\n",
    "        q = 2\n",
    "        Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n",
    "        Prob_Total+= Prob_file\n",
    "    Prob_App = Prob_Total/len(app_files)    \n",
    "\n",
    "\n",
    "    #forward_series = pd.Series(forward_list)\n",
    "    if Prob_App == np.inf: Prob_App =float(0)\n",
    "    print(app, \" matched \", len(matched_image_df), \" set \", len(app_pairs_set), \" Prob \",Prob_App)\n",
    "    result_df.loc[app,'matched'] = len(matched_image_df)\n",
    "    result_df.loc[app,'prob'] = \"{:.4f}\".format(Prob_App)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    matched      prob\n",
      "Wireshark-W7x64     56416.0  0.726628\n",
      "Wireshark-W7x32    171330.0  0.774965\n",
      "Winzip17pro-W7x32     184.0  0.120595\n",
      "Winzip17pro-W7x64      95.0  0.107737\n",
      "sdelete-W7x32           8.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(result_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"/Users/seunfuta/Downloads/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list = catalog_df.app.unique()\n",
    "for app in app_list:\n",
    "    if app == 'Firefox19-W7x64':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_dict_set = {}\n",
    "        app_pairs_set = set() \n",
    "        for file in app_files:\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                #app_pairs_set.add(file_hashes.iloc[0])\n",
    "                app_dict_set[file]=set(file_hashes.iloc[0])\n",
    "            else:\n",
    "                app_dict_set[file] = set()\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                    #print(i, hash_pair)\n",
    "                    #app_pairs_set.add(hash_pair)\n",
    "                    app_dict_set[file].add(hash_pair)\n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        #for key,value in app_dict_set.items():\n",
    "            #print(key,len(value))\n",
    "        image_md5_list = list(matched_image_df.md5)\n",
    "        image_md5_pairs = list(map(lambda a, b: a + b, image_md5_list[:-1], image_md5_list[1:]))\n",
    "        for key,value in app_dict_set.items():\n",
    "            forward_list = list(map(lambda x: 1 if x in value else 0, image_md5_pairs))\n",
    "            #forward_x = list(map(lambda x: x if x in value else 0, image_md5_pairs))\n",
    "            forward_series = pd.Series(forward_list).value_counts()\n",
    "            if 1 in forward_series.index.values:\n",
    "                print(key,forward_series[1])#,\"\\n\",forward_x)\n",
    "        #print(app, \"matched\", len(matched_image_df), \"set\", len(app_pairs_set), \"valid\",forward_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list = catalog_df.app.unique()\n",
    "for app in app_list:\n",
    "    if app == 'Firefox19-W7x64':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_dict_set = {}\n",
    "        app_pairs_set = set() \n",
    "        for file in app_files:\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                #app_pairs_set.add(file_hashes.iloc[0])\n",
    "                app_dict_set[file]=set(file_hashes.iloc[0])\n",
    "            else:\n",
    "                app_dict_set[file] = set()\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                    #print(i, hash_pair)\n",
    "                    #app_pairs_set.add(hash_pair)\n",
    "                    app_dict_set[file].add(hash_pair)\n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        #for key,value in app_dict_set.items():\n",
    "            #print(key,len(value))\n",
    "        image_md5_list = list(matched_image_df.md5)\n",
    "        image_md5_pairs = list(map(lambda a, b: a + b, image_md5_list[:-1], image_md5_list[1:]))\n",
    "        for key,value in app_dict_set.items():\n",
    "            forward_list = list(map(lambda x: 1 if x in value else 0, image_md5_pairs))\n",
    "            forward_x = list(map(lambda x: x if x in value else 0, image_md5_pairs))\n",
    "            forward_series = pd.Series(forward_list).value_counts()\n",
    "            if 1 in forward_series.index.values:\n",
    "                print(key,forward_series[1],\"\\n\",forward_x)\n",
    "        #print(app, \"matched\", len(matched_image_df), \"set\", len(app_pairs_set), \"valid\",forward_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "CATALOG_DB_PATH = \"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "catalog_conn = sqlite3.connect(CATALOG_DB_PATH)\n",
    "catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_conn)\n",
    "print(\"original length \",len(catalog_df))\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "catalog_conn.close()\n",
    "print(\"catalog app length, \", len(catalog_df))\n",
    "print(catalog_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(catalog_df[catalog_df.app == 'TrueCrypt63-WinXP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appx_df = catalog_df[catalog_df.app == 'TrueCrypt63-WinXP']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9897bb9d3ea6b47cb59a3fa29a33cee83df786d8baa248772bb7eb2ce311867"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('scan_match_validate_all_mpi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
