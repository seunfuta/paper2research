{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length  6826014\n",
      "catalog app length,  6546710\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "CATALOG_DB_PATH = \"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "catalog_conn = sqlite3.connect(CATALOG_DB_PATH)\n",
    "catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_conn)\n",
    "print(\"original length \",len(catalog_df))\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "catalog_conn.close()\n",
    "print(\"catalog app length, \", len(catalog_df))\n",
    "#return appdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image length  15413093\n",
      "current image length  14703514\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DB_PATH = \"/Volumes/Samsung_T5/M57/pat2.db\"\n",
    "image_conn = sqlite3.connect(IMAGE_DB_PATH)\n",
    "image_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize'])\n",
    "image_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, files.inode, files.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize \\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id;\", image_conn)\n",
    "print(\"original image length \",len(image_df))\n",
    "image_df = image_df[image_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "image_df = image_df[image_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "image_df = image_df[image_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "image_df = image_df[image_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "print(\"current image length \",len(image_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wireshark-W7x64  matched  5239  set  668  Prob  0.004153327669608866\n",
      "Wireshark-W7x32  matched  5893  set  671  Prob  0.007217902258553911\n",
      "Winzip17pro-W7x32  matched  22010  set  172  Prob  0.2499943206842112\n",
      "Winzip17pro-W7x64  matched  21698  set  175  Prob  0.21929526947629407\n",
      "sdelete-W7x32  matched  31  set  5  Prob  0.38655778726414197\n",
      "sdelete-W7x64  matched  31  set  3  Prob  0.64426297877357\n",
      "OfficePro2003-WinXP  matched  21115  set  3348  Prob  0.010939224878364143\n",
      "OfficePro2003-W7x64  matched  19469  set  3235  Prob  0.009969058434300264\n",
      "OfficePro2003-W7x32  matched  20576  set  3233  Prob  0.010742690690693455\n",
      "Winrar5beta-W7x32  matched  360  set  47  Prob  0.165369568008191\n",
      "Firefox19-WinXP  matched  1475  set  109  Prob  0.06469444399475519\n",
      "Winrar5beta-W7x64  matched  360  set  47  Prob  0.165369568008191\n",
      "Firefox19-W7x32  matched  1475  set  109  Prob  0.06469444399475519\n",
      "HxD171-W7x32  matched  1374  set  15  Prob  0.0\n",
      "Firefox19-W7x64  matched  1484  set  207  Prob  0.034060056462936215\n",
      "Thunderbird2-WinXP  matched  1101  set  208  Prob  0.031124460012488586\n",
      "Python264-WinXP  matched  91931  set  3014  Prob  0.07013739650000551\n",
      "eraser-W7x32  matched  288  set  21  Prob  0.0802016232947351\n",
      "Chrome28-W7x64  matched  9627  set  1005  Prob  0.018108055140336945\n",
      "Chrome28-WinXP  matched  10210  set  912  Prob  0.01917746579773871\n",
      "Chrome28-W7x32  matched  9625  set  1004  Prob  0.01867721845134348\n",
      "Safari157-W7x32  matched  12172  set  1317  Prob  0.14248628364782404\n",
      "Safari157-WinXP  matched  12139  set  1288  Prob  0.14417458694370128\n",
      "Safari157-W7x64  matched  12168  set  1298  Prob  0.14680400320631132\n",
      "TrueCrypt63-WinXP  matched  1014  set  16  Prob  0.2448340710524478\n",
      "AdvancedKeylogger-WinXP  matched  24  set  30  Prob  0.013524899893556219\n",
      "InvisibleSecrets21-WinXP  matched  211  set  25  Prob  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/d__51l693s13d_yt81j0qp9r0000gn/T/ipykernel_41384/279786015.py:42: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPX-W7x32  matched  0  set  14  Prob  0.0\n",
      "UPX-W7x64  matched  0  set  14  Prob  0.0\n",
      "                          matched    prob\n",
      "Wireshark-W7x64            5239.0  0.0042\n",
      "Wireshark-W7x32            5893.0  0.0072\n",
      "Winzip17pro-W7x32         22010.0  0.2500\n",
      "Winzip17pro-W7x64         21698.0  0.2193\n",
      "sdelete-W7x32                31.0  0.3866\n",
      "sdelete-W7x64                31.0  0.6443\n",
      "OfficePro2003-WinXP       21115.0  0.0109\n",
      "OfficePro2003-W7x64       19469.0  0.0100\n",
      "OfficePro2003-W7x32       20576.0  0.0107\n",
      "Winrar5beta-W7x32           360.0  0.1654\n",
      "Firefox19-WinXP            1475.0  0.0647\n",
      "Winrar5beta-W7x64           360.0  0.1654\n",
      "Firefox19-W7x32            1475.0  0.0647\n",
      "HxD171-W7x32               1374.0  0.0000\n",
      "Firefox19-W7x64            1484.0  0.0341\n",
      "Thunderbird2-WinXP         1101.0  0.0311\n",
      "Python264-WinXP           91931.0  0.0701\n",
      "eraser-W7x32                288.0  0.0802\n",
      "Chrome28-W7x64             9627.0  0.0181\n",
      "Chrome28-WinXP            10210.0  0.0192\n",
      "Chrome28-W7x32             9625.0  0.0187\n",
      "Safari157-W7x32           12172.0  0.1425\n",
      "Safari157-WinXP           12139.0  0.1442\n",
      "Safari157-W7x64           12168.0  0.1468\n",
      "TrueCrypt63-WinXP          1014.0  0.2448\n",
      "AdvancedKeylogger-WinXP      24.0  0.0135\n",
      "InvisibleSecrets21-WinXP    211.0  0.0000\n",
      "UPX-W7x32                     0.0  0.0000\n",
      "UPX-W7x64                     0.0  0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/d__51l693s13d_yt81j0qp9r0000gn/T/ipykernel_41384/279786015.py:42: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "app_list = catalog_df.app.unique()\n",
    "result_df = pd.DataFrame()\n",
    "for app in app_list:\n",
    "    #if app == 'OfficePro2003-W7x32':\n",
    "    app_df = catalog_df[catalog_df.app == app]\n",
    "    app_unique_md5s= app_df.md5.unique()\n",
    "    matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "    #print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "    #print(matched_image_df)\n",
    "    #lets create app sec pairs\n",
    "    app_files = app_df.filename.unique()\n",
    "    #print(app_files)\n",
    "    app_pairs_set = {} #dict #set() \n",
    "    for file in app_files:\n",
    "        file_hashpair_set = set()\n",
    "        files_df = app_df[app_df.filename == file]\n",
    "        #print(f'file {file} is of size {len(files_df)}')\n",
    "        file_hashes = files_df.md5\n",
    "        if len(file_hashes)< 2:\n",
    "            #print(file_hashes.iloc[0])\n",
    "            file_hashpair_set.add(file_hashes.iloc[0])\n",
    "        else:\n",
    "            for i in range(0, len(file_hashes)-1):\n",
    "                #print(file_hashes.iloc[i])\n",
    "                #print(file_hashes.iloc[int(i+1)])\n",
    "                hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "            #print(i, hash_pair)\n",
    "                file_hashpair_set.add(hash_pair)\n",
    "        app_pairs_set[file] = file_hashpair_set \n",
    "    #print(f\"set size is {len(app_pairs_set)}\")\n",
    "    lst2 = list(matched_image_df.md5)\n",
    "    lst2_pairs = list(map(lambda a, b: a + b, lst2[:-1], lst2[1:]))\n",
    "    Prob_Total = 0\n",
    "    for file in app_files:\n",
    "        #x = 0 #setting a default value\n",
    "        forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "        x= forward_list.count(1)\n",
    "        t= len(forward_list)+0.0000000001\n",
    "        s = 1\n",
    "        q = 2\n",
    "        Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n",
    "        Prob_Total+= Prob_file\n",
    "    Prob_App = Prob_Total/len(app_files)    \n",
    "\n",
    "\n",
    "    #forward_series = pd.Series(forward_list)\n",
    "    if Prob_App == np.inf: Prob_App =float(0)\n",
    "    print(app, \" matched \", len(matched_image_df), \" set \", len(app_pairs_set), \" Prob \",Prob_App)\n",
    "    result_df.loc[app,'matched'] = len(matched_image_df)\n",
    "    result_df.loc[app,'prob'] = \"{:.4f}\".format(Prob_App)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    matched      prob\n",
      "Wireshark-W7x64     56416.0  0.726628\n",
      "Wireshark-W7x32    171330.0  0.774965\n",
      "Winzip17pro-W7x32     184.0  0.120595\n",
      "Winzip17pro-W7x64      95.0  0.107737\n",
      "sdelete-W7x32           8.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(result_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"/Users/seunfuta/Downloads/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list = catalog_df.app.unique()\n",
    "for app in app_list:\n",
    "    if app == 'Firefox19-W7x64':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_dict_set = {}\n",
    "        app_pairs_set = set() \n",
    "        for file in app_files:\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                #app_pairs_set.add(file_hashes.iloc[0])\n",
    "                app_dict_set[file]=set(file_hashes.iloc[0])\n",
    "            else:\n",
    "                app_dict_set[file] = set()\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                    #print(i, hash_pair)\n",
    "                    #app_pairs_set.add(hash_pair)\n",
    "                    app_dict_set[file].add(hash_pair)\n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        #for key,value in app_dict_set.items():\n",
    "            #print(key,len(value))\n",
    "        image_md5_list = list(matched_image_df.md5)\n",
    "        image_md5_pairs = list(map(lambda a, b: a + b, image_md5_list[:-1], image_md5_list[1:]))\n",
    "        for key,value in app_dict_set.items():\n",
    "            forward_list = list(map(lambda x: 1 if x in value else 0, image_md5_pairs))\n",
    "            #forward_x = list(map(lambda x: x if x in value else 0, image_md5_pairs))\n",
    "            forward_series = pd.Series(forward_list).value_counts()\n",
    "            if 1 in forward_series.index.values:\n",
    "                print(key,forward_series[1])#,\"\\n\",forward_x)\n",
    "        #print(app, \"matched\", len(matched_image_df), \"set\", len(app_pairs_set), \"valid\",forward_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list = catalog_df.app.unique()\n",
    "for app in app_list:\n",
    "    if app == 'Firefox19-W7x64':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_dict_set = {}\n",
    "        app_pairs_set = set() \n",
    "        for file in app_files:\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                #app_pairs_set.add(file_hashes.iloc[0])\n",
    "                app_dict_set[file]=set(file_hashes.iloc[0])\n",
    "            else:\n",
    "                app_dict_set[file] = set()\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                    #print(i, hash_pair)\n",
    "                    #app_pairs_set.add(hash_pair)\n",
    "                    app_dict_set[file].add(hash_pair)\n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        #for key,value in app_dict_set.items():\n",
    "            #print(key,len(value))\n",
    "        image_md5_list = list(matched_image_df.md5)\n",
    "        image_md5_pairs = list(map(lambda a, b: a + b, image_md5_list[:-1], image_md5_list[1:]))\n",
    "        for key,value in app_dict_set.items():\n",
    "            forward_list = list(map(lambda x: 1 if x in value else 0, image_md5_pairs))\n",
    "            forward_x = list(map(lambda x: x if x in value else 0, image_md5_pairs))\n",
    "            forward_series = pd.Series(forward_list).value_counts()\n",
    "            if 1 in forward_series.index.values:\n",
    "                print(key,forward_series[1],\"\\n\",forward_x)\n",
    "        #print(app, \"matched\", len(matched_image_df), \"set\", len(app_pairs_set), \"valid\",forward_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "CATALOG_DB_PATH = \"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "catalog_conn = sqlite3.connect(CATALOG_DB_PATH)\n",
    "catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                FROM files \\\n",
    "                INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_conn)\n",
    "print(\"original length \",len(catalog_df))\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "catalog_conn.close()\n",
    "print(\"catalog app length, \", len(catalog_df))\n",
    "print(catalog_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(catalog_df[catalog_df.app == 'TrueCrypt63-WinXP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appx_df = catalog_df[catalog_df.app == 'TrueCrypt63-WinXP']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9897bb9d3ea6b47cb59a3fa29a33cee83df786d8baa248772bb7eb2ce311867"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('scan_match_validate_all_mpi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
