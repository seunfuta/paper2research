{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length  6826014\n",
      "catalog app length,  6546710\n",
      "/Users/seunfuta/Downloads/NIST/IMG/sdelete-W7x64.db\n",
      "original image length  6415822\n",
      "current image length  875101\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "class args:\n",
    "    i = \"/Users/seunfuta/Downloads/NIST/IMG/sdelete-W7x64.db\" #Wireshark-W7x64.db\"\n",
    "    c = \"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\"\n",
    "    o = \"/Users/seunfuta/Downloads/NIST/OLUSCAN/\"\n",
    "if __name__ == '__main__':\n",
    "    #parser = argparse.ArgumentParser(description='Olu method')\n",
    "    #parser.add_argument('-c', action=\"store\", default=\"/Users/seunfuta/Downloads/NIST/OluDB_combo_v3.db\", help='catalog path')\n",
    "    #parser.add_argument('-i', action=\"store\", default=\"/Users/seunfuta/Downloads/NIST/IMG/Wireshark-W7x64.db\", help=\"image path folder\")\n",
    "    #parser.add_argument('-o', action=\"store\", default=\"/Users/seunfuta/Downloads/NIST/OLUSCAN/\", help='output csv')\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    #onlyfiles = [f for f in listdir(args.i) if isfile(join(args.i, f))]\n",
    "    #for file in onlyfiles:\n",
    "    #    print(\"IMAGE \"+str(onlyfiles.index(file)) +\" out of \"+str(len(onlyfiles)))\n",
    "    #    main(join(args.i+file))\n",
    "    #main(join(args.i))\n",
    "    #def main(imagefilepath):\n",
    "    CATALOG_DB_PATH = args.c\n",
    "    catalog_conn = sqlite3.connect(CATALOG_DB_PATH)\n",
    "    catalog_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize','app','app_id'])\n",
    "    catalog_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, block_hashes.inode, block_hashes.filename, block_hashes.file_offset, \\\n",
    "                    block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize , files.app, files.app_id\\\n",
    "                    FROM files \\\n",
    "                    INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id \\\n",
    "                    and files.inode = block_hashes.inode and files.filename=block_hashes.filename;\", catalog_conn)\n",
    "    print(\"original length \",len(catalog_df))\n",
    "    catalog_df = catalog_df[catalog_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    catalog_df = catalog_df[catalog_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "    catalog_conn.close()\n",
    "    print(\"catalog app length, \", len(catalog_df))\n",
    "    #############\n",
    "    print(args.i)#magefilepath)\n",
    "    IMAGE_DB_PATH = args.i#imagefilepath\n",
    "    image_conn = sqlite3.connect(IMAGE_DB_PATH)\n",
    "    image_df = pd.DataFrame(columns=['obj_id', 'inode', 'filename','file_offset', 'len','md5','sha1', 'partition', 'filesize'])\n",
    "    image_df = pd.read_sql_query(\"SELECT block_hashes.obj_id, files.inode, files.filename, block_hashes.file_offset, \\\n",
    "                    block_hashes.len, block_hashes.md5, block_hashes.sha1, files.partition,files.filesize \\\n",
    "                    FROM files \\\n",
    "                    INNER JOIN block_hashes ON files.obj_id = block_hashes.obj_id;\", image_conn)\n",
    "    print(\"original image length \",len(image_df))\n",
    "    image_df = image_df[image_df.md5 != 'bf619eac0cdf3f68d496ea9344137e8b']\n",
    "    image_df = image_df[image_df.md5 != 'de03fe65a6765caa8c91343acc62cffc']\n",
    "    image_df = image_df[image_df.md5 != '85eba416ce0ee0951d1d93e73b191b75']\n",
    "    image_df = image_df[image_df.md5 != '1b5c2cbf1e37f6b0d33751269ae707af']\n",
    "    print(\"current image length \",len(image_df))\n",
    "    ##############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s7/d__51l693s13d_yt81j0qp9r0000gn/T/ipykernel_46734/814131228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mhash2pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muniq_hash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_hash_uniq_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniq_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#image_hashes_dict = OrderedDict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash2pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_2_file_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash2pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_2_file_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash2pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_2_file_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DataFrame'"
     ]
    }
   ],
   "source": [
    "    from collections import OrderedDict\n",
    "    app_list = catalog_df.app.unique() #['Wireshark-W7x64'] #\n",
    "    result_df = pd.DataFrame()\n",
    "    for app in ['TrueCrypt63-WinXP']:#app_list:\n",
    "        #if app == 'OfficePro2003-W7x32':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        #print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_pairs_set = {} #dict #set() \n",
    "        #lst2 = list(matched_image_df.md5)\n",
    "        #lst2_pairs = list(map(lambda a, b: a + b, lst2[:-1], lst2[1:]))\n",
    "        Prob_Total = float(0)\n",
    "        file1 = app_files[0]\n",
    "        for file in list(file1):#app_files:\n",
    "            #file_hash_dict = {}\n",
    "            #file_hashpair_set = set()\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            '''\n",
    "            if len(file_hashes)< 2:\n",
    "                 #print(file_hashes.iloc[0])\n",
    "                file_hashpair_set.add(file_hashes.iloc[0])\n",
    "            else:\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                #print(i, hash_pair)\n",
    "                    file_hashpair_set.add(hash_pair)\n",
    "            app_pairs_set[file] = file_hashpair_set \n",
    "            '''\n",
    "            file_hash_uniq_list = files_df.md5.unique()\n",
    "            hash2pos = {}\n",
    "            #result = hash2pos[]\n",
    "            image_2_file_df = image_df[image_df.md5.isin(file_hash_uniq_list)]\n",
    "            for uniq_hash in file_hash_uniq_list:\n",
    "                hash2pos[uniq_hash] = list(map(lambda x: file_hash_uniq_list.index(x), uniq_hash))\n",
    "            #image_hashes_dict = OrderedDict()\n",
    "            result = list(map(lambda a, b, c: np.where((b-a ==1) & (c-b==1),1,0), hash2pos[image_2_file_df[:-2]], hash2pos[image_2_file_df[1:-1]], hash2pos[image_2_file_df[2:]]))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        total_app_sector_size = 0\n",
    "        for value in app_pairs_set.values():\n",
    "            total_app_sector_size += len(value)\n",
    "        Prob_Total = float(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for file in app_files:\n",
    "            #x = 0 #setting a default value\n",
    "            forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "            \n",
    "            if 1 in forward_list:\n",
    "\n",
    "                result = np.where(np.array(forward_list) == 1)[0]\n",
    "                print(\"\\\"\",file, forward_list.count(1),result)\n",
    "            else:\n",
    "                print(\"no match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for file in app_files:\n",
    "            #x = 0 #setting a default value\n",
    "            forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "            x= forward_list.count(1)\n",
    "            t= len(forward_list)+0.0000000001\n",
    "            s = 1\n",
    "            q = 2\n",
    "            Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n",
    "            print(\"forward_list: \", len(forward_list),\"x FL(1): \", x, \"s: \", s, \"q: \", q ,\"probfile \", \"{:.4f}\".format(Prob_file), \"weight: \", len(app_pairs_set[file]), \"over \", total_app_sector_size)\n",
    "            #print(\"probfile \", \"{:.4f}\".format(Prob_file))\n",
    "            #print(\"weight: \", len(app_pairs_set[file]), \"over \", total_app_sector_size)\n",
    "            Prob_Total+= (float(Prob_file) * (float(len(app_pairs_set[file]))/float(total_app_sector_size)))\n",
    "            if (Prob_Total == float('inf')): Prob_Total =float(0)\n",
    "        Prob_App = \"{:.4f}\".format(Prob_Total)\n",
    "        print(\"TOTAL PROB: \", Prob_App)\n",
    "\n",
    "        #forward_series = pd.Series(forward_list)\n",
    "        #if Prob_App == np.inf: Prob_App =float(0)\n",
    "        #print(app, \" matched \", len(matched_image_df), \" set \", len(app_pairs_set), \" Prob \",Prob_App)\n",
    "        result_df.loc[app,'matched'] = len(matched_image_df)\n",
    "        result_df.loc[app,'prob'] = Prob_App\n",
    "    #result_df.replace([np.inf, -np.inf], float(0), inplace=True)\n",
    "    #print(result_df)\n",
    "    ###############\n",
    "    #result_df.to_csv(args.o+args.i.split(\"/\")[-1].split(\".\")[0]+\".csv\")\n",
    "    ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from math import e\n",
    "    app_list = catalog_df.app.unique() #['Wireshark-W7x64'] #\n",
    "    result_df = pd.DataFrame()\n",
    "    for app in app_list:\n",
    "        #if app == 'OfficePro2003-W7x32':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        #print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_pairs_set = {} #dict #set() \n",
    "        lst2 = list(matched_image_df.md5)\n",
    "        lst2_pairs = list(map(lambda a, b: a + b, lst2[:-1], lst2[1:]))\n",
    "        Prob_Total = float(0)\n",
    "        for file in app_files:\n",
    "            file_hashpair_set = set()\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                file_hashpair_set.add(file_hashes.iloc[0])\n",
    "            else:\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                #print(i, hash_pair)\n",
    "                    file_hashpair_set.add(hash_pair)\n",
    "            app_pairs_set[file] = file_hashpair_set \n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        total_app_sector_size = 0\n",
    "        for value in app_pairs_set.values():\n",
    "            total_app_sector_size += len(value)\n",
    "        Prob_Total = float(0)\n",
    "        for file in app_files:\n",
    "            #x = 0 #setting a default value\n",
    "            forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "            x= forward_list.count(1)\n",
    "            t= len(forward_list)+0.0000000001\n",
    "            s = 1\n",
    "            q = 2\n",
    "            p = 0.1\n",
    "            Prob_file = 1 - e**(-(x/(p*t))) + e**(-1/p)\n",
    "            #print(\"probfile \", \"{:.4f}\".format(Prob_file))\n",
    "            Prob_Total+= (float(Prob_file) * (float(len(app_pairs_set[file]))/float(total_app_sector_size)))\n",
    "            if (Prob_Total == float('inf')): Prob_Total =float(0)\n",
    "        Prob_App = \"{:.4f}\".format(Prob_Total)\n",
    "\n",
    "\n",
    "        #forward_series = pd.Series(forward_list)\n",
    "        #if Prob_App == np.inf: Prob_App =float(0)\n",
    "        print(app, \" matched \", len(matched_image_df), \" set \", len(app_pairs_set), \" Prob \",Prob_App)\n",
    "        result_df.loc[app,'matched'] = len(matched_image_df)\n",
    "        result_df.loc[app,'prob'] = Prob_App\n",
    "    #result_df.replace([np.inf, -np.inf], float(0), inplace=True)\n",
    "    print(result_df)\n",
    "    ###############\n",
    "    #result_df.to_csv(args.o+args.i.split(\"/\")[-1].split(\".\")[0]+\".csv\")\n",
    "    ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    app_list = catalog_df.app.unique() #['Wireshark-W7x64'] #\n",
    "    result_df = pd.DataFrame()\n",
    "    for app in app_list:\n",
    "        #if app == 'OfficePro2003-W7x32':\n",
    "        app_df = catalog_df[catalog_df.app == app]\n",
    "        app_unique_md5s= app_df.md5.unique()\n",
    "        matched_image_df = image_df[image_df.md5.isin(app_unique_md5s)]\n",
    "        #print(app,\" matched number of sectors in image \",len(matched_image_df))\n",
    "        #print(matched_image_df)\n",
    "        #lets create app sec pairs\n",
    "        app_files = app_df.filename.unique()\n",
    "        #print(app_files)\n",
    "        app_pairs_set = {} #dict #set() \n",
    "        lst2 = list(matched_image_df.md5)\n",
    "        lst2_pairs = list(map(lambda a, b: a + b, lst2[:-1], lst2[1:]))\n",
    "        Prob_Total = float(0)\n",
    "        for file in app_files:\n",
    "            file_hashpair_set = set()\n",
    "            files_df = app_df[app_df.filename == file]\n",
    "            #print(f'file {file} is of size {len(files_df)}')\n",
    "            \n",
    "            file_hashes = files_df.md5\n",
    "            if len(file_hashes)< 2:\n",
    "                #print(file_hashes.iloc[0])\n",
    "                file_hashpair_set.add(file_hashes.iloc[0])\n",
    "            else:\n",
    "                for i in range(0, len(file_hashes)-1):\n",
    "                    #print(file_hashes.iloc[i])\n",
    "                    #print(file_hashes.iloc[int(i+1)])\n",
    "                    hash_pair = file_hashes.iloc[i]+file_hashes.iloc[i+1]\n",
    "                #print(i, hash_pair)\n",
    "                    file_hashpair_set.add(hash_pair)\n",
    "            app_pairs_set[file] = file_hashpair_set \n",
    "        #print(f\"set size is {len(app_pairs_set)}\")\n",
    "        total_app_sector_size = 0\n",
    "        for value in app_pairs_set.values():\n",
    "            total_app_sector_size += len(value)\n",
    "        Prob_Total = float(0)\n",
    "        for file in app_files:\n",
    "            #x = 0 #setting a default value\n",
    "            forward_list = list(map(lambda x: 1 if x in app_pairs_set[file] else 0, lst2_pairs))\n",
    "            x= forward_list.count(1)\n",
    "            y = forward_list.count(0)\n",
    "            z = x + y\n",
    "            if z == 0: z = 1\n",
    "            #t= len(forward_list)+0.0000000001\n",
    "            #s = 1\n",
    "            #q = 2\n",
    "            #Prob_file = (1 - ((1/(x + s))**q))**(np.log(t))\n",
    "            Prob_file = float(x)/float(z)\n",
    "            #print(\"probfile \", \"{:.4f}\".format(Prob_file))\n",
    "            Prob_Total+= (float(Prob_file) * (float(len(app_pairs_set[file]))/float(total_app_sector_size)))\n",
    "            if (Prob_Total == float('inf')): Prob_Total =float(0)\n",
    "        Prob_App = \"{:.4f}\".format(Prob_Total)\n",
    "\n",
    "\n",
    "        #forward_series = pd.Series(forward_list)\n",
    "        #if Prob_App == np.inf: Prob_App =float(0)\n",
    "        print(app, \" matched \", len(matched_image_df), \" set \", len(app_pairs_set), \" Prob \",Prob_App)\n",
    "        result_df.loc[app,'matched'] = len(matched_image_df)\n",
    "        result_df.loc[app,'prob'] = Prob_App\n",
    "    #result_df.replace([np.inf, -np.inf], float(0), inplace=True)\n",
    "    print(result_df)\n",
    "    ###############\n",
    "    #result_df.to_csv(args.o+args.i.split(\"/\")[-1].split(\".\")[0]+\".csv\")\n",
    "    ################\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1895fe77d861caeaa821f2df72086efbb9754c9ce180e62170f24c0ec4bbaef9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('paper2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
